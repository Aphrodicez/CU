{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.2"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "F59BwNdMieQw"
      ]
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EsX9HcswkMhh"
      },
      "source": [
        "# Workshop 2.1 : web parsing with str functions\n",
        "We will crawl data from https://www.chula.ac.th/en/academics/faculties-and-schools/\n",
        "\n",
        "which is mirrored here https://comprogchula.github.io/\n",
        "\n",
        "<img src =\"https://github.com/Mixelon-tera/Workshop2_Datascraping_Resource/raw/master/source/intro_scraping.png\" width=\"800\">"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3pkX1wP3kMhi"
      },
      "source": [
        "import urllib\n",
        "import urllib.request as urq\n",
        "import os\n",
        "\n",
        "dir_path = os.path.dirname(os.path.realpath(\"__file__\"))\n",
        "print(dir_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F59BwNdMieQw"
      },
      "source": [
        "### Tip! \n",
        " \n",
        "#### สำหรับเรื่อง string ในภาษา python ต้องระวังเรื่อง escape character เรามักจะใช้เครื่องหมาย \\ นำหน้า escape character ดังนี้\n",
        "\n",
        "<img src=\"https://i2.wp.com/www.techpaste.com/wp-content/uploads/2014/06/Escape_Characters_Python.jpg?fit=441%2C425&ssl=1\" width=400>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9a5vdLTmkMhl"
      },
      "source": [
        "# TO DO 1 : Crawl \"Faculty Name\" [only 19 faculties] (1%)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UGZp9qD8kMhm"
      },
      "source": [
        "Print all Faculty name in Chulalongkorn University\n",
        "and print Number of Faculties like below image\n",
        "\n",
        "<img src=\"https://github.com/Mixelon-tera/Workshop2_Datascraping_Resource/raw/master/source/fac_name.png\" width=300>\n",
        "\n",
        "<img src=\"https://github.com/Mixelon-tera/Workshop2_Datascraping_Resource/raw/master/source/number_faculty.png\" width=300>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tF2I-cQFkMhn"
      },
      "source": [
        "### บางเว็บไซต์เราไม่สามารถใช้ urlopen ได้ตรงๆ เนื่องจากเว็บมีการป้องกันไว้ วิธีการแก้เบื้องต้นคือการใส่ header เพื่อหลอกเว็บไซต์ว่าเรากำลังใช้เว็บในการ request ข้อมูลเพจ ###\n",
        "### แต่ในการบ้านวันนี้เราสามารถใส่ url ลงใน urlopen ได้ตรงๆเลย เพราะเว็บไม่ได้มีการป้องกันไว้ ###\n",
        "\n",
        "home_url = 'https://comprogchula.github.io/'\n",
        "home_html = str(urq.urlopen(home_url).read().decode('utf-8'))\n",
        "\n",
        "# ---- TO DO 1 : Code Here ----\n",
        "\n",
        "s = home_html\n",
        "\n",
        "faculties = [str(x)[x.find('Faculty of') : x.find('</a></h3>')] for x in home_html.splitlines() if 'Faculty of ' in x][ : -1]\n",
        "\n",
        "print(*faculties, sep = '\\n')\n",
        "print('Number of Faculties :', len(faculties))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4J3G2YYEkMhq"
      },
      "source": [
        "# TO DO 2 : Crawl \"Faculty and Schools Image\" [21 faculties and schools] (1%)\n",
        "\n",
        "Print image's url and save image into folder 'faculty_image'\n",
        "\n",
        "#### Hint : save images into -> dir_path+\"/faculty_image\"+faculty_name\n",
        "\n",
        "<img src=\"https://github.com/pjumruspun/ComProg2021-Workshop/blob/main/Workshop-02-Scraping/images.png?raw=true\" width=600>\n",
        "\n",
        "<img src=\"https://github.com/pjumruspun/ComProg2021-Workshop/blob/main/Workshop-02-Scraping/images_dir.png?raw=true\" width=600>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z7XGFlJ972N3"
      },
      "source": [
        "#สร้าง folder ชื่อ faculty_image\n",
        "\n",
        "!mkdir -p faculty_image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6egHZ54tTMX2"
      },
      "source": [
        "### ขั้นตอนการอ่านและบันทึกไฟล์ภาพ\n",
        "\n",
        "1. อ่านภาพจากลิงค์\n",
        "* d = url.urlopen( [ลิงค์ของภาพ] )\n",
        "---\n",
        "2. สร้างไฟล์พร้อมระบุตำแหน่งที่จะเก็บไฟล์ภาพ \n",
        "* l = open( [ระบุตำแหน่งที่จะเก็บภาพ] )\n",
        "---\n",
        "\n",
        "3. บันทึกข้อมูลภาพไปยังตำแหน่งที่เก็บไฟล์ตามที่ระบุไว้ในข้อ (2.)\n",
        "* l.write(d.read())\n",
        "---\n",
        "\n",
        "4. ปิดไฟล์\n",
        "* l.close()\n",
        "---\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2JSrIjIHkMhq"
      },
      "source": [
        "# ---- TO DO 2 : Code Here ----\n",
        "\n",
        "faculty_image_urls = [str(x)[x.find('https') : -2] for x in home_html.splitlines() if 'data-src=' in x and 'image' in x]\n",
        "\n",
        "for x in faculty_image_urls:\n",
        "    print(x)\n",
        "    faculty_name = x[x.find('image/') + 6 : ]\n",
        "    d = urq.urlopen(x)\n",
        "    try:\n",
        "        l = open(dir_path + '/faculty_image/' + faculty_name, 'wb') # Write Binary\n",
        "    except:\n",
        "        l = open(dir_path + '\\\\faculty_image\\\\' + faculty_name, 'wb') # Write Binary\n",
        "    l.write(d.read())\n",
        "    l.close()\n",
        "\n",
        "print('Total images:', len(faculty_image_urls))\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wu9Lq8EYm_4O"
      },
      "source": [
        "# TO DO 3 : Crawl \"Faculty Telephone Number\" [19 Faculties] (1%)\n",
        "\n",
        "Print Tel. of each faculty in Chulalongkorn University\n",
        "\n",
        "*** Only Faculty ***\n",
        "\n",
        "<img src=\"https://github.com/pjumruspun/ComProg2021-Workshop/blob/main/Workshop-02-Scraping/tel.png?raw=true\" width=450>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7CUSb9KvkMht"
      },
      "source": [
        "# ---- TO DO 3 : Code Here ----\n",
        "\n",
        "urls = [str(x)[x.find('https:') : x.find('\">Faculty of')] for x in home_html.splitlines() if 'Faculty of ' in x][ : -1]\n",
        "\n",
        "for url in urls:\n",
        "  html = str(urq.urlopen(url).read().decode('utf-8'))\n",
        "  tels = [str(x).replace('</br>', '<br>') for x in html.splitlines() if 'wpcf-field-custom-content-contact' in x and 'Tel:' in x]\n",
        "  if len(tels) == 0:\n",
        "    tels = [str(x) for x in html.splitlines() if '<p><strong>Tel:' in x]\n",
        "  tel = ''.join([str(x)[x.find('+66') : x.find('<br>')] for x in tels]).replace('(0) ', '').replace('+66', '0')\n",
        "  print(url[url.find('faculty-of') : url.find('.html')])\n",
        "  print('\\t' + tel, sep = '\\n')\n",
        "\n",
        "print('Number of faculty:', len(urls))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O6qXu-BSkMhv"
      },
      "source": [
        "# TO DO 4: Crawl faculty of CP (1%)\n",
        "\n",
        "Current Faculty Members and Retired Faculty Members\n",
        "\n",
        "from https://www.cp.eng.chula.ac.th/en/about/faculty/\n",
        "\n",
        "*** Crawl only active members that have image ***\n",
        "\n",
        "**hint:** There are multiple strategies. To make it simple, we also accept a solution that list Dr. PITCHAYA as well. Another way is to check whether the image is the same filecmp.cmp https://docs.python.org/3/library/filecmp.html can do this. Or you can use if statements to exclude known exceptions.\n",
        "\n",
        "This is an old list. It may be incorrect.\n",
        "\n",
        "<img src=\"https://github.com/thcktw/Workshop2_Datascraping_Resource/raw/master/source/crawl_fac_member.png\" width=300>\n",
        "\n",
        "\n",
        "The correct answer should follow this picture.\n",
        "https://drive.google.com/file/d/1MlAf9hyVJeZZVfUMFiMMJlN7Ip3sfrsS/view?usp=drivesdk"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p member_image"
      ],
      "metadata": {
        "id": "2x1A2fW5gzq7"
      },
      "execution_count": 192,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DSh-mDUckMhw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "31f20ae3-b1bb-4768-be66-656e023c9c02"
      },
      "source": [
        "# ---- TO DO 4 : Code Here ----\n",
        "\n",
        "import filecmp\n",
        "\n",
        "dir_member_image = dir_path + '/member_image'\n",
        "\n",
        "def save_image(url, filename):\n",
        "  d = urq.urlopen(url)\n",
        "  try:\n",
        "    l = open(dir_member_image + '/' + filename + '.png', 'wb') # Write Binary\n",
        "  except:\n",
        "    l = open(dir_member_image + '\\\\' + filename + '.png', 'wb')\n",
        "  l.write(d.read())\n",
        "  l.close()\n",
        "\n",
        "def has_image(url, filename):\n",
        "  save_image(url, filename)\n",
        "  return not filecmp.cmp(dir_member_image + '/' + filename + '.png', dir_member_image + '/empty_image.png')\n",
        "\n",
        "# ---- Main ----\n",
        "\n",
        "save_image('https://mis.cp.eng.chula.ac.th/view.php?q=instructor/picture&v=badge&key=10019319', 'empty_image')\n",
        "\n",
        "cp_url = 'https://www.cp.eng.chula.ac.th/en/about/faculty/'\n",
        "cp_html = str(urq.urlopen(cp_url).read().decode('utf-8'))\n",
        "\n",
        "status = ['Current Faculty Members', 'Retired Faculty Members', 'Deceased aculty Members']\n",
        "\n",
        "for x in status:\n",
        "  cp_html = cp_html.replace(x, 'Split Faculty Members')\n",
        "\n",
        "index = 0\n",
        "\n",
        "for tables in cp_html.split('Split Faculty Members')[1 : 3]:\n",
        "  print(status[index])\n",
        "  print()\n",
        "\n",
        "  for table in tables.split('<tr class=\"instructorRow\"')[1:]:\n",
        "    s = table[table.find('http://mis.cp.eng.chula.ac.th/view.php?q=instructor/picture') : ]\n",
        "    image_url = s[ : s.find('\\\" alt')].replace('amp;', '')\n",
        "    s = s[s.find('<a href=\"/en/about/faculty/') : ]\n",
        "    name = s[ : s.find('</a></p>')].split('<p>')[-1].strip()\n",
        "    if has_image(image_url, name):\n",
        "      print(name)\n",
        "  \n",
        "  print()\n",
        "  index += 1"
      ],
      "execution_count": 193,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current Faculty Members\n",
            "\n",
            "PROF. DR. BOONSERM KIJSIRIKUL\n",
            "PROF. DR. PRABHAS CHONGSTITVATANA\n",
            "ASSOC. PROF. DR. ATHASIT SURARERKS\n",
            "ASSOC. PROF. DR. ATIWONG SUCHATO\n",
            "ASSOC. PROF. DR. CHOTIRAT RATANAMAHATANA\n",
            "ASSOC. PROF. DR. DUANGDAO  WICHADAKUL\n",
            "ASSOC. PROF. DR. KRERK PIROMSOPA\n",
            "ASSOC. PROF. DR. KULTIDA ROJVIBOONCHAI\n",
            "ASSOC. PROF. DR. NUTTAPONG CHENTANEZ\n",
            "ASSOC. PROF. DR. PEERAPON VATEEKUL\n",
            "ASSOC. PROF. DR. PROADPRAN PUNYABUKKANA\n",
            "ASSOC. PROF. DR. SETHA PAN-NGUM\n",
            "ASSOC. PROF. DR. TARATIP SUWANNASART\n",
            "ASSOC. PROF. DR. THANARAT CHALIDABHONGSE\n",
            "ASSOC. PROF. DR. TWITTIE SENIVONGSE\n",
            "ASSOC. PROF. DR. VISHNU KOTRAJARAS\n",
            "ASSOC. PROF. DR. WIWAT VATANAWOOD\n",
            "ASSOC. PROF. DR. YACHAI LIMPIYAKORN\n",
            "ASSOC. PROF. NAKORNTHIP PROMPOON\n",
            "ASST. PROF. DR. ARTHIT THONGTAK\n",
            "ASST. PROF. DR. ATTAWITH SUDSANG\n",
            "ASST. PROF. DR. KUNWADEE  SRIPANIDKULCHAI\n",
            "ASST. PROF. DR. NATAWUT NUPAIROJ\n",
            "ASST. PROF. DR. NATTEE NIPARNAN\n",
            "ASST. PROF. DR. PIZZANU KANONGCHAIYOS\n",
            "ASST. PROF. DR. SUKREE SINTHUPINYO\n",
            "ASST. PROF. DR. VEERA MUANGSIN\n",
            "ASST. PROF. CHATE PATANOTHAI\n",
            "DR. EKAPOL  CHUANGSUWANICH\n",
            "DR. JESSADA THUTKAWKORAPIN\n",
            "DR. NUENGWONG TUAYCHAROEN\n",
            "DR. PITTIPOL  KANTAVAT\n",
            "DR. PUNNARAI  SIRICHAROEN\n",
            "THONGCHAI ROJAKANGSADAN\n",
            "\n",
            "Retired Faculty Members\n",
            "\n",
            "ASSOC. PROF. DR. PORNSIRI MUENCHAISRI\n",
            "Assc.Prof. Dr. SARTID VONGPRADHIP\n",
            "ASSOC. PROF. DR. SOMCHAI PRASITJUTRAKUL\n",
            "Assc.Prof. Dr. WANCHAI RIVEPIBOON\n",
            "Assc.Prof. MANDHANA PRAKANSAMUT\n",
            "Asst.Prof. Dr. SUEBSKUL PHIPHOBMONGKOL\n",
            "Asst.Prof. BOONCHAI SOWANWANICHAKUL\n",
            "Asst.Prof. Korbkul Tejavanija\n",
            "Asst.Prof. THANAWAN CHANTARATANAPIBUL\n",
            "Dr. YUNYONG TENG-AMNUAY\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fmL5uX5RWp2f"
      },
      "source": [
        "# To Do 5\n",
        "\n",
        "ทดลองดึงข้อมูลจาก dek-d.com ดูสิ :)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6r8NQmAYkMhy"
      },
      "source": [
        "dd_url = 'https://www.dek-d.com/home/writer/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kAFkUJU0YCaF"
      },
      "source": [
        "ลองรันโค๊ดบรรทัดด้านล่างดู"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GVrU9jG0XjvF"
      },
      "source": [
        "html = str(urq.urlopen(dd_url).read().decode('utf-8'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O9G_ZbZsYMUh"
      },
      "source": [
        "จะพบว่าเกิด error ขึ้นเนื่องจากเว็บ dek-d มีการป้องกันไว้ \n",
        "\n",
        "หากเราต้อง scrape จะต้องส่ง user-agent เช่น Web-browser, Accept-Charset, Accept-Encoding เป็นต้น เพื่อหลอกเว็บไซต์ว่าเรากำลังใช้เว็บในการ request ข้อมูลเพจ"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WeVk4zsWZLZ0"
      },
      "source": [
        "headers={'User-Agent': 'Mozilla/5.0 (Windows; U; Windows NT 5.1; en-US; rv:1.9.0.7) Gecko/2009021910 Firefox/3.0.7'} \n",
        "\n",
        "\n",
        "dd_request = urq.Request(dd_url,None,headers) \n",
        "dd_html = str(urq.urlopen(dd_request).read().decode('utf-8'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HNO0U9aYf0Id"
      },
      "source": [
        "ลองดึงข้อมูล title นิยายจากเว็บ https://www.dek-d.com/home/writer/ ดูสิ!!!\n",
        "\n",
        "\n",
        "#### ตัวอย่าง output \n",
        "\n",
        "<img src=\"https://github.com/Mixelon-tera/Workshop2_Datascraping_Resource/raw/master/source/dek_d_fiction.png\" width=400>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OQjDoNJKXESX"
      },
      "source": [
        "# ---- OPTIONAL : Code Here ----\n",
        "\n",
        "titles = [str(x.split('data-v-39cd99b3>')[1]) for x in dd_html.split('class=\"content__title\"')[1:]]\n",
        "titles = [str(x)[ : x.find('</h3>')] for x in titles]\n",
        "\n",
        "print(*titles, sep = '\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Q1XHZBwMgHad"
      },
      "execution_count": 194,
      "outputs": []
    }
  ]
}